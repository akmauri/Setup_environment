# Ralph Process - Progress and Learnings

This file stores learnings, patterns, and context discovered during Ralph iterations.
It is append-only - never overwrite, only add new entries.

Each entry should include:
- Timestamp
- Story ID and title
- Key learnings
- Patterns discovered
- Gotchas to avoid
- Useful context for future iterations

---

[2026-01-15 12:00:00] Story 1.1: Project Setup & Repository Structure

Learnings:
- Monorepo structure already exists with apps/web, apps/api, packages/shared, packages/ui, packages/config, packages/db
- TypeScript strict mode is enabled in root and all packages
- ESLint and Prettier are configured with shared rules
- Husky pre-commit hooks are configured and working
- CI/CD pipeline exists in .github/workflows/ci.yml
- Docker Compose was missing n8n and ComfyUI services - added them
- README needed architecture overview and development guidelines - enhanced it

Patterns:
- TypeScript path aliases require baseUrl to be set in tsconfig.json for proper resolution
- Next.js apps need @/* path alias configured in tsconfig.json with baseUrl
- Docker Compose services should include all required services (PostgreSQL, Redis, n8n, ComfyUI)

Gotchas:
- Pre-existing code in apps/api has linting errors (empty catch blocks, console statements, test files not in tsconfig)
- These are pre-existing issues and should be addressed in a separate code quality story
- ESLint configuration for API package needs to exclude test files or include them in tsconfig

Useful Context:
- Project uses Turborepo for monorepo management
- All packages extend root tsconfig.json for consistent TypeScript configuration
- Pre-commit hooks run: lint, format:check, type-check
- CI/CD pipeline runs: lint, format:check, type-check, test, build
- Docker Compose services: postgres (5432), redis (6379), n8n (5678), comfyui (8188)

---

[2026-01-15 13:00:00] Story 1.2: Multi-Tenant Database Architecture

Learnings:
- Prisma is used for migrations and ORM, but tenant schemas require raw SQL for dynamic schema creation
- Schema-per-tenant architecture uses PostgreSQL search_path to route queries to correct tenant schema
- Tenant schema names follow pattern: tenant_{uuid_with_underscores}
- All tenant-specific tables (users, content, social_accounts, workflows, publish_jobs, analytics, teams, comments, notifications) are created in tenant schemas
- Public schema contains system-wide tables: tenants, migrations, countries, timezones, platforms
- PgBouncer connection pooling is configured in docker-compose for production-ready setup
- Database middleware (tenantDbMiddleware) extracts tenant_id from JWT token and sets search_path automatically

Patterns:
- Tenant schema creation: CREATE SCHEMA tenant_{id}, then apply migrations
- Tenant schema deletion: DROP SCHEMA CASCADE for GDPR compliance
- Database connection uses search_path to route queries: SET search_path TO tenant_{id}, public
- All tenant tables have updated_at triggers using shared function update_updated_at_column()
- Foreign keys in tenant schemas reference tables within the same schema (no cross-schema FKs)

Gotchas:
- Prisma doesn't natively support dynamic schemas - use raw SQL for tenant schema operations
- Schema names must be sanitized (replace hyphens with underscores) for PostgreSQL compatibility
- Tenant schema migrations must be applied after schema creation, not via Prisma migrate
- search_path must be set per connection/transaction, not globally
- PgBouncer uses transaction pooling mode for best compatibility with search_path

Useful Context:
- Database connection string: Use DATABASE_URL for primary, DATABASE_READ_URL for read replicas
- PgBouncer port: 6432 (default), PostgreSQL direct: 5432
- Backup strategy documented in docs/DATABASE_BACKUP_STRATEGY.md
- Read replica configuration documented in docs/DATABASE_READ_REPLICA.md
- Migration rollback procedures documented in packages/db/docs/MIGRATION_ROLLBACK.md
- Tenant service functions: createTenant, createTenantSchema, deleteTenantSchema, applyTenantSchemaMigration

---

[2026-01-15 14:00:00] Story 1.3: User Authentication System

Learnings:
- Comprehensive authentication system implemented with email/password and OAuth (Google, Microsoft, Okta)
- Password hashing uses bcrypt with configurable salt rounds (minimum 10, default 10)
- JWT tokens use separate secrets for access (JWT_SECRET) and refresh (JWT_REFRESH_SECRET) tokens
- Access tokens expire in 15 minutes, refresh tokens expire in 30 days
- Token rotation implemented: refresh tokens are single-use, old session deleted when new pair is issued
- Email verification tokens expire in 24 hours, password reset tokens expire in 1 hour
- Rate limiting implemented: 5 attempts per 15 minutes for auth endpoints, 100 requests per 15 minutes for general endpoints
- 2FA (TOTP) implemented using speakeasy library with QR code generation
- Session management tracks device info (user agent, IP address) and last activity
- All database queries use parameterized queries (Prisma.sql) to prevent SQL injection
- OAuth user creation automatically creates default tenant if user doesn't have one

Patterns:
- Authentication routes organized in apps/api/src/routes/auth.routes.ts
- Services separated by concern: auth.service.ts, jwt.service.ts, password.service.ts, token.service.ts, oauth.service.ts, totp.service.ts, session.service.ts, email.service.ts
- OAuth config centralized in apps/api/src/config/oauth.config.ts
- Rate limiting middleware uses in-memory store (should use Redis in production)
- Token hashing uses SHA-256 for secure storage
- All auth endpoints use createAuthRateLimitMiddleware() for stricter rate limiting
- Session table created dynamically per tenant schema using ensureSessionsTable()

Gotchas:
- Duplicate imports cause TypeScript errors - always check for duplicate import statements
- hashToken function was imported multiple times in session.service.ts (fixed)
- OAuth tokens should be stored encrypted in production (currently TODO in user.service.ts)
- Rate limiting uses in-memory store which won't work across multiple server instances - need Redis for production
- Tenant resolution for OAuth users uses simplified email domain lookup - should use proper user-tenant association table in production

Useful Context:
- JWT_SECRET and JWT_REFRESH_SECRET must be set in environment variables
- BCRYPT_SALT_ROUNDS defaults to 10 if not set (minimum enforced)
- OAuth providers require client ID and secret in environment: GOOGLE_CLIENT_ID, GOOGLE_CLIENT_SECRET, etc.
- Email service requires SMTP configuration (SMTP_HOST, SMTP_PORT, SMTP_USER, SMTP_PASS)
- All auth routes mounted at /api/v1/auth
- OAuth callback routes: /api/v1/auth/callback/:provider (google, microsoft, okta)
- Refresh token endpoint: POST /api/v1/auth/refresh
- Logout endpoint: POST /api/v1/auth/logout
- 2FA endpoints: POST /api/v1/auth/2fa/enable, POST /api/v1/auth/2fa/verify, POST /api/v1/auth/2fa/disable

---

[2026-01-15 15:00:00] Story 1.4: Basic User Management

Learnings:
- User profile management implemented with timezone and preferences support
- Email change flow requires verification of new email address (24-hour token expiry)
- Account deletion implements soft delete with 30-day retention period for GDPR compliance
- Activity logging tracks all profile changes with timestamp, IP address, and user agent
- User data export provides complete JSON export for GDPR compliance
- Profile endpoint returns subscription tier from tenant record
- Preferences stored as JSONB in database for flexible schema
- Migration function added to update existing user tables with new columns (timezone, preferences, email change fields, deleted_at)
- Activity logs table created per tenant schema to track user actions

Patterns:
- Profile updates log changes to activity_logs table before applying updates
- Soft delete pattern: set deleted_at timestamp instead of hard delete
- Email change uses same verification token pattern as email verification
- User preferences use JSONB for flexible schema (notifications, theme, language, date format)
- All user queries filter by deleted_at IS NULL to exclude soft-deleted accounts
- Subscription tier retrieved from tenant record, not stored in user table

Gotchas:
- Prisma.sql template literals require Prisma.raw() for SQL expressions like type casts (::uuid, ::jsonb, ::timestamp)
- JSON.stringify() must be called before using in Prisma.raw() to avoid template literal issues
- Activity logs table created dynamically per tenant using ensureActivityLogsTable()
- Email change verification requires separate endpoint (not same as initial email verification)
- Account deletion requires password confirmation even for OAuth users (if password_hash exists)

Pending Features:
- Avatar file upload with image validation (max 5MB, JPG/PNG/WebP) - requires multipart/form-data handling
- S3-compatible storage integration for avatar uploads - requires AWS SDK or MinIO setup
- Note: Profile currently accepts avatar URLs via PUT /api/v1/user/profile. File upload can be added when S3 storage is configured.

Useful Context:
- User profile endpoint: GET /api/v1/user/profile
- Update profile endpoint: PUT /api/v1/user/profile (supports name, picture URL, timezone, preferences)
- Email change request: POST /api/v1/user/change-email
- Email change verification: POST /api/v1/user/verify-email-change
- Account deletion: DELETE /api/v1/user/account (requires password in body)
- Data export: GET /api/v1/user/export (returns JSON file download)
- Activity logs stored in activity_logs table per tenant schema
- User preferences structure: { notifications: { email, push, inApp }, theme, language, dateFormat }
- Migration function migrateUsersTable() safely adds new columns to existing user tables

---

[2026-01-15 16:00:00] Story 1.5: Health Check & System Status

Learnings:
- Health check system implemented with basic and detailed endpoints
- Version information extracted from package.json and git commit hash
- Database health check executes SELECT 1 query with response time measurement
- Redis health check uses PING command with 5-second timeout
- External service checks (S3, email) verify configuration availability
- Health check results cached for 30 seconds using node-cache
- Prometheus metrics endpoint at /metrics with custom metrics registry
- Health check failure detection triggers alert hooks for monitoring integration
- Overall health status determined by component status (ok/degraded/down)
- Detailed health check runs all checks in parallel for performance

Patterns:
- Health check routes placed before tenant middleware (no tenant context needed)
- Component status includes response time for performance monitoring
- Caching prevents excessive database queries on health check endpoints
- Prometheus metrics updated automatically during health checks
- Alert hooks registered for monitoring system integration (email, Slack, PagerDuty)
- Health status codes: 200 for ok/degraded, 503 for down

Gotchas:
- Package.json path is relative to process.cwd() - use apps/api/package.json in monorepo
- Git commit hash requires git to be available or GIT_COMMIT_HASH env variable
- Redis client creation fails gracefully if REDIS_URL not configured
- S3 and email checks verify configuration, not actual connectivity (for performance)
- Health check caching uses node-cache with 30-second TTL
- Prometheus metrics use prom-client library with custom registry
- Alert hooks are non-blocking to prevent health check delays

Useful Context:
- Basic health endpoint: GET /health (returns status, timestamp, version, responseTime)
- Detailed health endpoint: GET /health/detailed (returns all component statuses)
- Prometheus metrics endpoint: GET /metrics (returns Prometheus format)
- Health check service: apps/api/src/services/health.service.ts
- Health check routes: apps/api/src/routes/health.routes.ts
- Metrics service: apps/api/src/services/metrics.service.ts
- Redis service: apps/api/src/services/redis.service.ts
- Version info extracted from package.json and git
- Cache TTL: 30 seconds for both basic and detailed health checks
- Alert hooks can be registered via registerAlertHook() function
- Health status: 'ok' (all components healthy), 'degraded' (non-critical components down), 'down' (critical components down)

---

[2026-01-15 17:00:00] Story 2.1: YouTube OAuth Integration

Learnings:
- YouTube OAuth uses Google OAuth infrastructure with YouTube-specific scopes
- Token encryption implemented using AES-256-GCM with environment variable key
- Social accounts stored in tenant schema with encrypted tokens
- Token refresh implements rotation (old refresh token invalidated, new one issued)
- Tier limits enforced per platform (free: 0, creator: 3, professional: 10, agency: 50, etc.)
- Account labeling added to social_accounts table via migration
- YouTube Data API v3 used for channel information retrieval
- Token health check validates tokens using YouTube API
- Token revocation implemented on account disconnection

Patterns:
- OAuth config extended to support YouTube provider with YouTube scopes
- Encryption service uses AES-256-GCM with IV and auth tag stored with encrypted data
- Social account service handles encryption/decryption automatically
- Token refresh service implements token rotation pattern
- Tier service centralizes limit checking logic
- YouTube routes follow RESTful pattern: /api/v1/social/youtube/*
- Account operations require authentication and ownership verification
- Token expiry tracked in database for auto-refresh scheduling

Gotchas:
- YouTube uses Google OAuth, so can reuse Google OAuth infrastructure
- Encryption key must be 32 bytes (256 bits) for AES-256
- Token format: iv:authTag:encrypted (all hex strings)
- Social accounts table label column added via migration (DO $$ block)
- Token rotation means old refresh token becomes invalid after refresh
- Tier limits checked before allowing new account connections
- YouTube API requires access token in Authorization header
- Channel info retrieval uses /youtube/v3/channels endpoint with mine=true

Useful Context:
- YouTube OAuth connect: GET /api/v1/social/youtube/connect
- YouTube OAuth callback: GET /api/v1/social/youtube/callback
- List YouTube accounts: GET /api/v1/social/youtube/accounts
- Disconnect account: DELETE /api/v1/social/youtube/accounts/:accountId
- Update label: PUT /api/v1/social/youtube/accounts/:accountId/label
- Token health: GET /api/v1/social/youtube/accounts/:accountId/health
- Encryption key: ENCRYPTION_KEY environment variable (32 bytes hex or string)
- YouTube scopes: youtube.upload, youtube.force-ssl, youtube.readonly
- Token expiry: Access tokens expire in 1 hour, refresh tokens are long-lived
- Auto-refresh: Tokens refreshed 5 minutes before expiry (shouldRefreshToken function)
- Tier limits service: apps/api/src/services/tier.service.ts
- Social account service: apps/api/src/services/social-account.service.ts
- YouTube service: apps/api/src/services/youtube.service.ts
- Token refresh service: apps/api/src/services/token-refresh.service.ts

---

[2026-01-15 18:00:00] Story 2.2: Instagram OAuth Integration

Learnings:
- Instagram OAuth uses Facebook Login (Facebook OAuth infrastructure)
- Requires Facebook App with Instagram permissions
- Instagram account must be Professional (Business or Creator) and connected to Facebook Page
- Long-lived tokens (60 days) vs short-lived (1 hour) - requires token exchange
- Facebook Page selection required before Instagram account connection
- Token refresh uses Facebook Graph API token exchange endpoint
- Account info retrieved from Instagram Graph API
- Facebook uses same token for access and refresh (unlike YouTube)
- Error handling needed for: non-professional accounts, unconnected pages, permission denials

Patterns:
- Facebook OAuth config added with Instagram-specific scopes
- Instagram service handles Facebook Graph API operations
- Facebook Page selection in callback flow (can select which page's Instagram account)
- Long-lived token exchange after initial OAuth flow
- Professional account validation before storing connection
- Token refresh service updated to handle Instagram/Facebook token pattern
- Instagram routes follow same RESTful pattern as YouTube routes
- Account operations require authentication and ownership verification
- Error handling with specific error codes for different failure scenarios

Gotchas:
- Instagram requires Facebook Business Manager setup
- Instagram account must be Professional (Business or Creator), not Personal
- Facebook Page must have Instagram account connected before OAuth
- Long-lived tokens expire in 60 days (not 1 hour like YouTube)
- Facebook uses same token for access and refresh (unlike YouTube which has separate tokens)
- Token exchange endpoint: /oauth/access_token with grant_type=fb_exchange_token
- Instagram Graph API requires page access token (not user access token)
- Account verification status requires separate API call
- Error messages must be user-friendly for common issues

Useful Context:
- Instagram OAuth connect: GET /api/v1/social/instagram/connect
- Instagram OAuth callback: GET /api/v1/social/instagram/callback?page_id=...
- Get Facebook Pages: GET /api/v1/social/instagram/pages?access_token=...
- List Instagram accounts: GET /api/v1/social/instagram/accounts
- Disconnect account: DELETE /api/v1/social/instagram/accounts/:accountId
- Update label: PUT /api/v1/social/instagram/accounts/:accountId/label
- Token health: GET /api/v1/social/instagram/accounts/:accountId/health
- Facebook App ID: FACEBOOK_APP_ID environment variable
- Facebook App Secret: FACEBOOK_APP_SECRET environment variable
- Facebook redirect URI: FACEBOOK_REDIRECT_URI environment variable
- Instagram scopes: instagram_basic, instagram_content_publish, pages_read_engagement, pages_show_list
- Token expiry: Long-lived tokens expire in 60 days (5184000 seconds)
- Instagram service: apps/api/src/services/instagram.service.ts
- Instagram routes: apps/api/src/routes/instagram.routes.ts
- Facebook OAuth config: apps/api/src/config/oauth.config.ts (facebookOAuthConfig)

---

[2026-01-15 19:00:00] Story 2.3: TikTok OAuth Integration

Learnings:
- TikTok OAuth uses standard OAuth 2.0 flow
- Requires TikTok Developer account and app creation
- Account must be Creator or Business (not Personal) and age 18+ for API access
- TikTok API uses client_key and client_secret (not client_id/client_secret)
- Token response structure may vary (data wrapper vs direct)
- Daily upload limit: 20 videos per account per day
- Token refresh uses TikTok OAuth refresh endpoint
- Account info retrieved from TikTok User Info API
- Token validation via TikTok API
- Refresh tokens have separate expiry (refresh_expires_in)

Patterns:
- TikTok OAuth config added with TikTok-specific scopes (video.upload, user.info.basic)
- TikTok service handles TikTok API operations
- Token exchange uses client_key/client_secret (TikTok-specific naming)
- Account type validation assumed if OAuth succeeds (TikTok enforces during OAuth)
- Daily upload limit stored in metadata (20 videos per day)
- Token refresh service updated to handle TikTok token pattern
- TikTok routes follow same RESTful pattern as YouTube/Instagram routes
- Account operations require authentication and ownership verification
- Refresh token expiry tracked separately from access token expiry

Gotchas:
- TikTok uses client_key and client_secret (not client_id/client_secret)
- Token response may be wrapped in data object or direct
- Account type and age validation enforced by TikTok during OAuth (not via API)
- Daily upload limit: 20 videos per account per day (hard limit)
- Refresh tokens have separate expiry (refresh_expires_in field)
- TikTok API endpoints: open.tiktokapis.com (not www.tiktok.com)
- User info API requires specific fields parameter
- Token validation requires making API call (no simple endpoint)

Useful Context:
- TikTok OAuth connect: GET /api/v1/social/tiktok/connect
- TikTok OAuth callback: GET /api/v1/social/tiktok/callback
- List TikTok accounts: GET /api/v1/social/tiktok/accounts
- Disconnect account: DELETE /api/v1/social/tiktok/accounts/:accountId
- Update label: PUT /api/v1/social/tiktok/accounts/:accountId/label
- Token health: GET /api/v1/social/tiktok/accounts/:accountId/health
- TikTok Client Key: TIKTOK_CLIENT_KEY environment variable
- TikTok Client Secret: TIKTOK_CLIENT_SECRET environment variable
- TikTok redirect URI: TIKTOK_REDIRECT_URI environment variable
- TikTok scopes: video.upload, user.info.basic
- Token expiry: Access tokens expire in 1 hour (3600 seconds), refresh tokens have separate expiry
- Daily upload limit: 20 videos per account per day
- TikTok service: apps/api/src/services/tiktok.service.ts
- TikTok routes: apps/api/src/routes/tiktok.routes.ts
- TikTok OAuth config: apps/api/src/config/oauth.config.ts (tiktokOAuthConfig)

---

[2026-01-15 20:00:00] Story 2.4: Twitter/X OAuth Integration

Learnings:
- Twitter/X uses Twitter API v2 OAuth 2.0
- Requires Twitter Developer account and app creation
- Refresh token rotation: new refresh token issued on each refresh (old one invalidated)
- Rate limits: Tweet limits per 15-minute window (varies by tier)
- Account verification status via Twitter API v2
- Token refresh uses Twitter OAuth refresh endpoint
- Account info retrieved from Twitter API v2 User Lookup
- Error handling needed for: suspended accounts, rate limits, permission issues
- Rate limit headers included in API responses (x-rate-limit-*)
- Twitter uses Basic Auth for token exchange (client_id:client_secret base64)
- Twitter API v2 endpoints: api.twitter.com/2/*

Patterns:
- Twitter OAuth config added with Twitter API v2 scopes (tweet.write, users.read, offline.access)
- Twitter service handles Twitter API v2 operations
- Token exchange uses Basic Auth (not form-encoded client credentials)
- Refresh token rotation implemented (new refresh token on each refresh)
- Rate limit information parsed from response headers
- Account status checking for suspended accounts
- Token refresh service updated to handle Twitter token rotation pattern
- Twitter routes follow same RESTful pattern as other platforms
- Account operations require authentication and ownership verification
- Error handling with specific error codes for different failure scenarios

Gotchas:
- Twitter uses Basic Auth for token exchange (not form-encoded client_id/client_secret)
- Refresh token rotation: old refresh token becomes invalid after refresh
- Rate limits tracked via response headers (x-rate-limit-limit, x-rate-limit-remaining, x-rate-limit-reset)
- Account suspension returns 403 status with error details
- Twitter API v2 uses different endpoint structure than v1.1
- User info requires specific fields parameter
- Token validation requires making API call (no simple endpoint)
- Rate limit reset is Unix timestamp (not ISO date)

Useful Context:
- Twitter OAuth connect: GET /api/v1/social/twitter/connect
- Twitter OAuth callback: GET /api/v1/social/twitter/callback
- List Twitter accounts: GET /api/v1/social/twitter/accounts
- Disconnect account: DELETE /api/v1/social/twitter/accounts/:accountId
- Update label: PUT /api/v1/social/twitter/accounts/:accountId/label
- Token health: GET /api/v1/social/twitter/accounts/:accountId/health
- Twitter Client ID: TWITTER_CLIENT_ID environment variable
- Twitter Client Secret: TWITTER_CLIENT_SECRET environment variable
- Twitter redirect URI: TWITTER_REDIRECT_URI environment variable
- Twitter scopes: tweet.write, users.read, offline.access
- Token expiry: Access tokens expire in 2 hours (7200 seconds)
- Refresh token rotation: New refresh token issued on each refresh
- Rate limits: Tracked via x-rate-limit-* headers in API responses
- Twitter service: apps/api/src/services/twitter.service.ts
- Twitter routes: apps/api/src/routes/twitter.routes.ts
- Twitter OAuth config: apps/api/src/config/oauth.config.ts (twitterOAuthConfig)

---

[2026-01-15 21:00:00] Story 2.5: LinkedIn OAuth Integration

Learnings:
- LinkedIn OAuth uses standard OAuth 2.0 flow
- Requires LinkedIn Developer account and app creation
- Long-lived tokens (60 days) vs short-lived (1 hour) - need token exchange
- Support for both personal profiles and company pages
- Company page connection requires admin access verification
- Token refresh uses LinkedIn refresh token endpoint
- Account info retrieved from LinkedIn Profile API (OpenID Connect) and Organization API
- Error handling needed for: permission issues, account access problems
- Account type stored in metadata to distinguish personal vs company
- LinkedIn uses OpenID Connect scopes (profile, email, openid) - r_liteprofile is deprecated

Patterns:
- LinkedIn OAuth config added with LinkedIn-specific scopes (openid, profile, email, w_member_social, rw_organization_admin)
- LinkedIn service handles LinkedIn API operations
- Support for both personal profiles (via userinfo endpoint) and company pages (via Organization API)
- Company page connection requires admin access verification via organizationalEntityAcls
- Account type stored in metadata (personal vs company)
- Token refresh service updated to handle LinkedIn token pattern
- LinkedIn routes follow same RESTful pattern as other platforms
- Account operations require authentication and ownership verification
- Company pages endpoint allows user to select which company page to connect

Gotchas:
- LinkedIn deprecated r_liteprofile and r_emailaddress in favor of OpenID Connect (profile, email, openid)
- Long-lived tokens obtained via token exchange (not direct from OAuth)
- Company page connection requires rw_organization_admin scope and admin access
- Organization API requires X-Restli-Protocol-Version: 2.0.0 header
- Company page details require separate API call after getting list
- Account type must be stored in metadata to distinguish personal vs company
- Token exchange for long-lived tokens may not be directly available (uses refresh token instead)

Useful Context:
- LinkedIn OAuth connect: GET /api/v1/social/linkedin/connect
- LinkedIn OAuth callback: GET /api/v1/social/linkedin/callback?account_type=personal|company&company_id=...
- Get company pages: GET /api/v1/social/linkedin/companies?access_token=...
- List LinkedIn accounts: GET /api/v1/social/linkedin/accounts
- Disconnect account: DELETE /api/v1/social/linkedin/accounts/:accountId
- Update label: PUT /api/v1/social/linkedin/accounts/:accountId/label
- Token health: GET /api/v1/social/linkedin/accounts/:accountId/health
- LinkedIn Client ID: LINKEDIN_CLIENT_ID environment variable
- LinkedIn Client Secret: LINKEDIN_CLIENT_SECRET environment variable
- LinkedIn redirect URI: LINKEDIN_REDIRECT_URI environment variable
- LinkedIn scopes: openid, profile, email, w_member_social, rw_organization_admin
- Token expiry: Long-lived tokens expire in 60 days (5184000 seconds)
- LinkedIn service: apps/api/src/services/linkedin.service.ts
- LinkedIn routes: apps/api/src/routes/linkedin.routes.ts
- LinkedIn OAuth config: apps/api/src/config/oauth.config.ts (linkedinOAuthConfig)

---

[2026-01-15 22:00:00] Story 2.6: Facebook OAuth Integration

Learnings:
- Facebook OAuth uses Facebook Login (already implemented for Instagram)
- Long-lived Page Access Tokens never expire (unlike user tokens which expire in 60 days)
- Token exchange: Exchange short-lived user token for long-lived user token, then get Page Access Token
- Page selection: User must have Admin or Editor role on the page
- Page Access Tokens obtained from /me/accounts endpoint are already long-lived
- Page info retrieved from Facebook Graph API
- Crossposting: Check if Instagram account exists for same Facebook Page ID
- Token health: Long-lived Page tokens don't expire, but can be revoked
- Page insights: Access verified via pages_read_engagement scope

Patterns:
- Facebook Pages OAuth config added with Pages-specific scopes (pages_manage_posts, pages_read_engagement, pages_show_list)
- Facebook service handles Facebook Graph API operations for Pages
- Token exchange: User token → Long-lived user token → Page Access Token
- Page Access Tokens stored (never expire unless revoked)
- Crossposting option displayed in metadata if Instagram connected
- Facebook routes follow same RESTful pattern as other platforms
- Account operations require authentication and ownership verification
- Page selection endpoint allows user to choose which page to connect

Gotchas:
- Page Access Tokens never expire (set far future date for tracking)
- Page Access Tokens obtained from /me/accounts are already long-lived (no additional exchange needed)
- User must have Admin or Editor role on page (enforced by Facebook)
- Crossposting requires Instagram account connected to same Facebook Page
- Page insights access requires pages_read_engagement scope
- Token revocation revokes both user and page tokens

Useful Context:
- Facebook OAuth connect: GET /api/v1/social/facebook/connect
- Facebook OAuth callback: GET /api/v1/social/facebook/callback?page_id=...
- Get Facebook Pages: GET /api/v1/social/facebook/pages?access_token=...
- List Facebook Pages: GET /api/v1/social/facebook/accounts
- Disconnect page: DELETE /api/v1/social/facebook/accounts/:accountId
- Update label: PUT /api/v1/social/facebook/accounts/:accountId/label
- Token health: GET /api/v1/social/facebook/accounts/:accountId/health
- Facebook App ID: FACEBOOK_APP_ID environment variable (same as Instagram)
- Facebook App Secret: FACEBOOK_APP_SECRET environment variable (same as Instagram)
- Facebook Pages redirect URI: FACEBOOK_PAGES_REDIRECT_URI environment variable
- Facebook Pages scopes: pages_manage_posts, pages_read_engagement, pages_show_list
- Token expiry: Page Access Tokens never expire (unless revoked)
- Facebook service: apps/api/src/services/facebook.service.ts
- Facebook routes: apps/api/src/routes/facebook.routes.ts
- Facebook Pages OAuth config: apps/api/src/config/oauth.config.ts (facebookPagesOAuthConfig)

---
